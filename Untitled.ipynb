{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect,join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import (Flask, render_template, jsonify, request, redirect)\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine= create_engine(\"postgres://wtzcxlhtevtgnn:a611ddfea80402e93d32df58dad93c3dfe320544d635b77e14e9bb8936eeca9e@ec2-52-86-116-94.compute-1.amazonaws.com:5432/d5hl5ab4698nnc\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "session=Session(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SQL_Pull(budget):\n",
    "    #Using Pandas for Data Analysis\n",
    "    #  Read the appraisal Table\n",
    "    appraisal=pd.read_sql_table('appraisal',engine)\n",
    "\n",
    "     # Calculate % of change of value between 2018 and 2019\n",
    "    appraisal_2018=appraisal.loc[appraisal.tax_year==2018,:]\n",
    "    appraisal_2019=appraisal.loc[appraisal.tax_year==2019,:]\n",
    "    appraisal_df=pd.merge(appraisal_2019,appraisal_2018,on='account', suffixes=('_2019','_2018'))\n",
    "    appraisal_df['pct_value_change']=(appraisal_df['total_appraised_value_2019']-appraisal_df['total_appraised_value_2018'])\\\n",
    "                                  /appraisal_df['total_appraised_value_2018']*100\n",
    "    results_df=appraisal_df[['id_2019','account','total_appraised_value_2019', 'pct_value_change']]\n",
    "    \n",
    "    #Read properties table\n",
    "    properties_df=pd.read_sql_table('properties',engine)\n",
    "    results_df=pd.merge(results_df,properties_df,on=\"account\")\n",
    "    del results_df['address']\n",
    "\n",
    "    #Read crime table and merge to results\n",
    "    crime_df=pd.read_sql_table('crime',engine)\n",
    "    crime_df=crime_df.rename(columns={'Zip_Code':'Zip_code'})\n",
    "    crime_aggr=crime_df.groupby(['Zip_code']).count()['Offense_Count']\n",
    "    crime_aggr_df=pd.DataFrame(crime_aggr)\n",
    "    results_df=pd.merge(results_df,crime_aggr_df,on=\"Zip_code\")\n",
    "    \n",
    "    #Read property_school table and merge to results\n",
    "    property_school_df=pd.read_sql_table('property_school',engine)\n",
    "    results_df=pd.merge(results_df,property_school_df,on=\"account\")\n",
    "    \n",
    "    #Read school table and merge to results\n",
    "    school_df=pd.read_sql_table('school',engine)\n",
    "    results_df=pd.merge(results_df,school_df,on=['school_id','school_type'])\n",
    "\n",
    "    #Add flood ranking\n",
    "    #3- High Risk\n",
    "    #2 - Medium Risk\n",
    "    #1- Low Risk\n",
    "    results_df.loc[(results_df['flood_description']=='AREA OF MINIMAL FLOOD HAZARD'),'flood_risk']=1\n",
    "    results_df.loc[(results_df['flood_description']=='0.2 PCT ANNUAL CHANCE FLOOD HAZARD'),'flood_risk']=2\n",
    "    results_df.loc[(results_df['flood_description']=='FLOODWAY'),'flood_risk']=3\n",
    "    results_df.loc[(results_df['flood_description']=='High-Risk Flood Zone'),'flood_risk']=3\n",
    "    del results_df['flood_description']\n",
    "    del results_df['name']\n",
    "    del results_df['address']\n",
    "    del results_df['city']\n",
    "    del results_df['zip_code']\n",
    "    del results_df['district_id']\n",
    "    del results_df['latitude_y']\n",
    "    del results_df['longitude_y']\n",
    "    results_df=results_df.rename(columns={'latitude_x':'latitude', 'longitude_x':'longitude'})\n",
    "\n",
    "    #Count the house sale per neighborhood in 2019 and merge results\n",
    "    results_df['sales2019']=np.where(results_df['new_owner_date']>'2018-12-31',1,0)\n",
    "    sales=results_df.groupby('neighborhood_code')['sales2019'].sum()\n",
    "    sales=pd.DataFrame(sales)\n",
    "    sales=sales.rename(columns={'sales2019':'sales_neighborhood_2019'})\n",
    "    results_df=pd.merge(results_df,sales, on=\"neighborhood_code\")\n",
    "    del results_df['sales2019']\n",
    "    \n",
    "    #  Read the neighborhoods Table\n",
    "    neighborhoods_df=pd.read_sql_table('neighborhoods',engine)\n",
    "    results_df=pd.merge(results_df,neighborhoods_df,on='neighborhood_code')\n",
    "    \n",
    "    # Filter by budget on year 2019\n",
    "    results_df=results_df.loc[results_df.total_appraised_value_2019<=budget,:]\n",
    "    \n",
    "    print('data pull complete')\n",
    "    return (results_df) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores (dictionaryOfUserInput):\n",
    "    w_budget = dictionaryOfUserInput[\"budget\"]\n",
    "    w_sales = dictionaryOfUserInput[\"sales\"]\n",
    "    w_crime = dictionaryOfUserInput[\"crime\"]\n",
    "    w_schools = dictionaryOfUserInput[\"schools\"]\n",
    "    w_acreage = dictionaryOfUserInput[\"acreage\"]\n",
    "    w_SQ_FT = dictionaryOfUserInput[\"sqft\"]\n",
    "    w_flood = dictionaryOfUserInput[\"flood\"]\n",
    "    w_change = dictionaryOfUserInput[\"change\"]\n",
    "\n",
    "    # call SQL_Pull function to query the database and create a dataframe\n",
    "    df = SQL_Pull(w_budget)\n",
    " \n",
    "    # Normalize data for each parameter\n",
    "    max=df['sales_neighborhood_2019'].max()\n",
    "    min=df['sales_neighborhood_2019'].min()\n",
    "    df[\"Sales Index\"]=(df['sales_neighborhood_2019']-min)/(max-min)*100\n",
    "    \n",
    "  \n",
    "    max=df['Offense_Count'].max()\n",
    "    min=df['Offense_Count'].min()\n",
    "    df[\"Crime Index\"]=(df['Offense_Count']-min)/(max-min)*100\n",
    "\n",
    "    max=df['school_rating'].max()\n",
    "    min=df['school_rating'].min()\n",
    "    df[\"School Rating Index\"]=(df['school_rating']-min)/(max-min)*100\n",
    "\n",
    "    max=df['acreage'].max()\n",
    "    min=df['acreage'].min()\n",
    "    df[\"Acreage Index\"]=(df['acreage']-min)/(max-min)*100\n",
    "\n",
    "    max=df['sq_ft'].max()\n",
    "    min=df['sq_ft'].min()\n",
    "    df[\"SQ_FT Index\"]=(df['sq_ft']-min)/(max-min)*100\n",
    "\n",
    "    max=df['flood_risk'].max()\n",
    "    min=df['flood_risk'].min()\n",
    "    df[\"Flood Risk Index\"]=(df['flood_risk']-min)/(max-min)*100\n",
    "\n",
    "    max=df['pct_value_change'].max()\n",
    "    df['Valuation Index']=df['pct_value_change']/max*100\n",
    "\n",
    "    # Calculate scores for each address.\n",
    "    total_weights=w_sales+w_crime+w_schools+w_acreage+w_SQ_FT+w_flood+w_change\n",
    "\n",
    "    # Add calculated scores to the dataframe\n",
    "    df[\"Sales Index_W\"]=w_sales*df['Sales Index']\n",
    "    df['Crime Index_W']= w_crime*df['Crime Index']\n",
    "    df[\"School Rating Index_W\"]=w_schools*df['School Rating Index']\n",
    "    df[\"Acreage Index_W\"]= w_acreage*df['Acreage Index']\n",
    "    df[\"SQ_FT_Index_W\"]= w_SQ_FT*df['SQ_FT Index']\n",
    "    df[\"Flood Risk Index_W\"]=w_flood*df['Flood Risk Index']\n",
    "    df['Valuation Index_W']= w_change*df['Valuation Index']\n",
    "\n",
    "    # Calculate total score per row\n",
    "    df[\"Score\"]=round((w_sales*df['Sales Index']-\n",
    "                                    w_crime*df['Crime Index']+\n",
    "                                    w_schools*df['School Rating Index']+\n",
    "                                    w_acreage*df['Acreage Index']+\n",
    "                                    w_SQ_FT*df['SQ_FT Index']-\n",
    "                                    w_flood*df['Flood Risk Index']+\n",
    "                                    w_change*df['Valuation Index'])/total_weights,2)\n",
    "\n",
    "    # convert the score to percentage and scale them\n",
    "    max=df[\"Score\"].max()\n",
    "    min=df[\"Score\"].min()\n",
    "    max=df[\"Score\"]=(df[\"Score\"]-min)/(max-min)*100\n",
    "\n",
    "    # look at only the parameters of interest\n",
    "    parameter_and_score = df[[\"Sales Index\",'Crime Index', 'School Rating Index',\n",
    "            'Acreage Index','SQ_FT Index', 'Flood Risk Index', 'Valuation Index','Score',\n",
    "            'total_appraised_value_2019','neighborhood']]\n",
    "\n",
    "    # group parameters by neighborhood name\n",
    "    neighborhood_group = parameter_and_score.groupby(['neighborhood']).mean()\n",
    "\n",
    "    # To get to the top list, neighnorhoods need positive valuation index and non-zero sales index\n",
    "    neighborhood_group=neighborhood_group.loc[(neighborhood_group['Valuation Index']>0)&(neighborhood_group['Sales Index']>0),:]\n",
    "\n",
    "    min=neighborhood_group['Valuation Index'].min()\n",
    "    max=neighborhood_group['Valuation Index'].max()\n",
    "    min=neighborhood_group['Valuation Index']=(neighborhood_group['Valuation Index']-min)/(max-min)*100\n",
    "\n",
    "    # sort scores\n",
    "    ranked_neighborhoods = neighborhood_group.sort_values('Score',ascending=False)\n",
    "\n",
    "    top5neighborhoods= ranked_neighborhoods.head()\n",
    "    \n",
    "    return top5neighborhoods.to_json('top5hoods.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_inputs={\"budget\":1000000, \"sales\":10, \"crime\":10, \"schools\":10, \"acreage\":10, \"sqft\":10,\"flood\":10, \"change\":10}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_2019</th>\n",
       "      <th>account</th>\n",
       "      <th>total_appraised_value_2019</th>\n",
       "      <th>pct_value_change</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Zip_code</th>\n",
       "      <th>neighborhood_code</th>\n",
       "      <th>acreage</th>\n",
       "      <th>new_owner_date</th>\n",
       "      <th>sq_ft</th>\n",
       "      <th>Offense_Count</th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_type</th>\n",
       "      <th>school_rating</th>\n",
       "      <th>flood_risk</th>\n",
       "      <th>sales_neighborhood_2019</th>\n",
       "      <th>neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>488</td>\n",
       "      <td>270520000008</td>\n",
       "      <td>152100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.76922</td>\n",
       "      <td>-95.35257</td>\n",
       "      <td>77002</td>\n",
       "      <td>7116.0</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>1998-08-26</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>4743</td>\n",
       "      <td>101912025</td>\n",
       "      <td>High</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAILE/SWINEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>489</td>\n",
       "      <td>270520000015</td>\n",
       "      <td>159132.0</td>\n",
       "      <td>5.919235</td>\n",
       "      <td>29.76902</td>\n",
       "      <td>-95.35256</td>\n",
       "      <td>77002</td>\n",
       "      <td>7116.0</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>4743</td>\n",
       "      <td>101912025</td>\n",
       "      <td>High</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAILE/SWINEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>490</td>\n",
       "      <td>270520000016</td>\n",
       "      <td>125150.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.76926</td>\n",
       "      <td>-95.35242</td>\n",
       "      <td>77002</td>\n",
       "      <td>7116.0</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>1988-01-02</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>4743</td>\n",
       "      <td>101912025</td>\n",
       "      <td>High</td>\n",
       "      <td>95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAILE/SWINEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>488</td>\n",
       "      <td>270520000008</td>\n",
       "      <td>152100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.76922</td>\n",
       "      <td>-95.35257</td>\n",
       "      <td>77002</td>\n",
       "      <td>7116.0</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>1998-08-26</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>4743</td>\n",
       "      <td>101912240</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAILE/SWINEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>489</td>\n",
       "      <td>270520000015</td>\n",
       "      <td>159132.0</td>\n",
       "      <td>5.919235</td>\n",
       "      <td>29.76902</td>\n",
       "      <td>-95.35256</td>\n",
       "      <td>77002</td>\n",
       "      <td>7116.0</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>4743</td>\n",
       "      <td>101912240</td>\n",
       "      <td>Elementary</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>HAILE/SWINEY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_2019       account  total_appraised_value_2019  pct_value_change  \\\n",
       "108      488  270520000008                    152100.0          0.000000   \n",
       "109      489  270520000015                    159132.0          5.919235   \n",
       "110      490  270520000016                    125150.0          0.000000   \n",
       "111      488  270520000008                    152100.0          0.000000   \n",
       "112      489  270520000015                    159132.0          5.919235   \n",
       "\n",
       "     latitude  longitude  Zip_code  neighborhood_code  acreage new_owner_date  \\\n",
       "108  29.76922  -95.35257     77002             7116.0   0.1286     1998-08-26   \n",
       "109  29.76902  -95.35256     77002             7116.0   0.0809     2015-01-08   \n",
       "110  29.76926  -95.35242     77002             7116.0   0.1149     1988-01-02   \n",
       "111  29.76922  -95.35257     77002             7116.0   0.1286     1998-08-26   \n",
       "112  29.76902  -95.35256     77002             7116.0   0.0809     2015-01-08   \n",
       "\n",
       "      sq_ft  Offense_Count  school_id school_type  school_rating  flood_risk  \\\n",
       "108  1598.0           4743  101912025        High             95         1.0   \n",
       "109  1308.0           4743  101912025        High             95         1.0   \n",
       "110  1836.0           4743  101912025        High             95         1.0   \n",
       "111  1598.0           4743  101912240  Elementary             75         1.0   \n",
       "112  1308.0           4743  101912240  Elementary             75         1.0   \n",
       "\n",
       "     sales_neighborhood_2019  neighborhood  \n",
       "108                        0  HAILE/SWINEY  \n",
       "109                        0  HAILE/SWINEY  \n",
       "110                        0  HAILE/SWINEY  \n",
       "111                        0  HAILE/SWINEY  \n",
       "112                        0  HAILE/SWINEY  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=SQL_Pull(250000)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation completed\n"
     ]
    }
   ],
   "source": [
    "scores(default_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RealEstate",
   "language": "python",
   "name": "realestate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
